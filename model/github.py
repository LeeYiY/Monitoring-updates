import base64

import requests
import os
import json
import yaml
from typing import List, Dict, Optional

# ------------------- é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆæ ¸å¿ƒï¼šæŒ‡å®šYAMLé…ç½®æ–‡ä»¶ä½ç½®ï¼‰ -------------------
REPO_CONFIG_YAML: str = "./repo_configs.yaml"  # å•ç‹¬çš„YAMLä»“åº“é…ç½®æ–‡ä»¶

# ------------------- å…¨å±€é…ç½®ï¼ˆæ‰€æœ‰ä»“åº“å…±ç”¨ï¼‰ -------------------
GITHUB_TOKEN: Optional[str] = ""  # GitHubä»¤ç‰Œï¼ˆæ— åˆ™è®¾ä¸ºNoneï¼Œé¿å…APIè¯·æ±‚é™åˆ¶ï¼‰
STATE_FILE: str = "./repo_states/downloaded_assets.json"  # æ‰€æœ‰ä»“åº“å…±ç”¨çš„ä¸‹è½½çŠ¶æ€æ–‡ä»¶
MAX_VERSIONS: int = 5  # é»˜è®¤è·å–æœ€æ–°çš„5ä¸ªç‰ˆæœ¬


# ------------------- å·¥å…·å‡½æ•°ï¼ˆæ–°å¢ï¼šåŠ è½½YAMLä»“åº“é…ç½®ï¼‰ -------------------
def load_repo_configs_from_yaml(config_file: str) -> List[Dict]:
    """
    ä»YAMLæ–‡ä»¶åŠ è½½å¹¶æ ¡éªŒä»“åº“é…ç½®
    :param config_file: YAMLé…ç½®æ–‡ä»¶è·¯å¾„
    :return: åˆæ³•çš„ä»“åº“é…ç½®åˆ—è¡¨
    :raises FileNotFoundError: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨
    :raises yaml.YAMLError: YAMLæ ¼å¼é”™è¯¯
    :raises ValueError: é…ç½®ç¼ºå°‘å¿…è¦å­—æ®µæˆ–æ ¼å¼éæ³•
    """
    # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config_file):
        raise FileNotFoundError(f"YAMLä»“åº“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{os.path.abspath(config_file)}")

    # 2. è¯»å–å¹¶è§£æYAMLæ–‡ä»¶
    try:
        with open(config_file, "r", encoding="utf-8") as f:
            config_data = yaml.safe_load(f)  # ä½¿ç”¨safe_loadé¿å…å®‰å…¨é£é™©
    except yaml.YAMLError as e:
        raise yaml.YAMLError(f"YAMLé…ç½®æ–‡ä»¶è§£æå¤±è´¥ï¼š{str(e)}")

    # 3. æ ¡éªŒé…ç½®æ ¹ç»“æ„ï¼ˆå¿…é¡»åŒ…å«"repos"å­—æ®µä¸”ä¸ºåˆ—è¡¨ï¼‰
    if "repos" not in config_data or not isinstance(config_data["repos"], list):
        raise ValueError("YAMLé…ç½®æ–‡ä»¶å¿…é¡»åŒ…å«ã€reposã€å­—æ®µï¼Œä¸”å€¼ä¸ºä»“åº“é…ç½®åˆ—è¡¨")

    # 4. æ ¡éªŒæ¯ä¸ªä»“åº“çš„å¿…è¦å­—æ®µï¼ˆç¡®ä¿é…ç½®å®Œæ•´ï¼‰
    required_fields = ["repo_owner", "repo_name", "base_save_dir", "state_key"]  # å¿…é€‰å­—æ®µ
    valid_repos = []
    for repo_idx, repo_config in enumerate(config_data["repos"], 1):
        # æ£€æŸ¥æ˜¯å¦ä¸ºå­—å…¸æ ¼å¼
        if not isinstance(repo_config, dict):
            raise ValueError(f"ç¬¬{repo_idx}ä¸ªä»“åº“é…ç½®æ ¼å¼é”™è¯¯ï¼šå¿…é¡»ä¸ºå­—å…¸ï¼ˆé”®å€¼å¯¹ï¼‰")

        # æ£€æŸ¥å¿…é€‰å­—æ®µæ˜¯å¦ç¼ºå¤±
        missing_fields = [field for field in required_fields if field not in repo_config]
        if missing_fields:
            raise ValueError(f"ç¬¬{repo_idx}ä¸ªä»“åº“é…ç½®ç¼ºå¤±å¿…è¦å­—æ®µï¼š{', '.join(missing_fields)}")

        # æ£€æŸ¥å­—æ®µå€¼æ˜¯å¦ä¸ºç©º
        for field in required_fields:
            if not repo_config[field] or str(repo_config[field]).strip() == "":
                raise ValueError(f"ç¬¬{repo_idx}ä¸ªä»“åº“çš„ã€{field}ã€å­—æ®µä¸èƒ½ä¸ºç©º")

        # æ·»åŠ åˆ°åˆæ³•é…ç½®åˆ—è¡¨
        valid_repos.append(repo_config)

    return valid_repos


# ------------------- å·¥å…·å‡½æ•°ï¼ˆå¤ç”¨é€»è¾‘ï¼šçŠ¶æ€ç®¡ç†ã€APIè¯·æ±‚ã€ä¸‹è½½ï¼‰ -------------------
def load_all_repos_downloaded_state() -> Dict[str, Dict[int, str]]:
    """åŠ è½½æ‰€æœ‰ä»“åº“çš„å·²ä¸‹è½½çŠ¶æ€ï¼ˆä»JSONçŠ¶æ€æ–‡ä»¶ï¼‰"""
    os.makedirs(os.path.dirname(STATE_FILE), exist_ok=True)  # ç¡®ä¿çŠ¶æ€æ–‡ä»¶ç›®å½•å­˜åœ¨
    if not os.path.exists(STATE_FILE):
        return {}

    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            state_data = json.load(f)
            # å°†JSONçš„å­—ç¬¦ä¸²Keyè½¬ä¸ºæ•´æ•°ï¼ˆä¸GitHub Asset IDç±»å‹ä¸€è‡´ï¼‰
            return {
                repo_key: {int(asset_id): asset_name for asset_id, asset_name in repo_state.items()}
                for repo_key, repo_state in state_data.items()
            }
    except json.JSONDecodeError:
        # çŠ¶æ€æ–‡ä»¶æŸåæ—¶å¤‡ä»½å¹¶è¿”å›ç©ºçŠ¶æ€
        backup_file = f"{STATE_FILE}.bak"
        os.rename(STATE_FILE, backup_file)
        print(f"âš ï¸  çŠ¶æ€æ–‡ä»¶æŸåï¼Œå·²å¤‡ä»½ä¸ºï¼š{os.path.basename(backup_file)}")
        return {}

def save_all_repos_downloaded_state(state: Dict[str, Dict[int, str]]) -> None:
    """ä¿å­˜æ‰€æœ‰ä»“åº“çš„å·²ä¸‹è½½çŠ¶æ€ï¼ˆåˆ°JSONçŠ¶æ€æ–‡ä»¶ï¼‰"""
    # å°†æ•´æ•°Keyè½¬ä¸ºå­—ç¬¦ä¸²ï¼ˆJSONä¸æ”¯æŒæ•´æ•°Keyï¼‰
    state_str_key = {
        repo_key: {str(asset_id): asset_name for asset_id, asset_name in repo_state.items()}
        for repo_key, repo_state in state.items()
    }
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state_str_key, f, ensure_ascii=False, indent=2)

def fetch_repo_releases(repo_owner: str, repo_name: str, max_versions: int = MAX_VERSIONS) -> List[Dict]:
    """
    è·å–ä»“åº“çš„Releasesï¼ˆåŒ…å«ç‰ˆæœ¬ä¿¡æ¯å’Œé™„ä»¶ï¼‰
    :param repo_owner: ä»“åº“æ‰€æœ‰è€…
    :param repo_name: ä»“åº“åç§°
    :param max_versions: æœ€å¤šè·å–çš„ç‰ˆæœ¬æ•°é‡ï¼Œé»˜è®¤ä¸ºå…¨å±€é…ç½®çš„MAX_VERSIONS
    :return: Releaseåˆ—è¡¨
    """
    headers = {"Authorization": f"token {GITHUB_TOKEN}"} if GITHUB_TOKEN else {}
    releases = []
    page = 1
    api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/releases"

    while len(releases) < max_versions:
        try:
            response = requests.get(
                api_url,
                headers=headers,
                params={"page": page, "per_page": min(100, max_versions - len(releases))},  # æ¯é¡µæœ€å¤šè·å–æ‰€éœ€å‰©ä½™æ•°é‡
                timeout=30
            )
            response.raise_for_status()  # è§¦å‘HTTPé”™è¯¯ï¼ˆå¦‚403é™æµã€404ä»“åº“ä¸å­˜åœ¨ï¼‰
        except requests.exceptions.RequestException as e:
            raise Exception(f"GitHub APIè¯·æ±‚å¤±è´¥ï¼š{str(e)}")

        current_releases = response.json()
        if not current_releases:
            break  # æ— æ›´å¤šReleasesæ—¶ç»ˆæ­¢åˆ†é¡µ
        
        # æ·»åŠ å½“å‰é¡µçš„Releasesï¼Œä½†ä¸è¶…è¿‡max_versions
        remaining_slots = max_versions - len(releases)
        releases.extend(current_releases[:remaining_slots])
        page += 1

    return releases

def sanitize_version(version: str) -> str:
    """æ¸…ç†ç‰ˆæœ¬å·ä¸­çš„éæ³•å­—ç¬¦ï¼Œç¡®ä¿å¯ä»¥ä½œä¸ºç›®å½•å"""
    invalid_chars = '/\\:*?"<>|'
    for char in invalid_chars:
        version = version.replace(char, '-')
    return version

def download_asset(asset: Dict, save_dir: str) -> bool:
    """ä¸‹è½½å•ä¸ªReleaseé™„ä»¶ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    asset_id = asset["id"]
    asset_name = asset["name"]
    download_url = asset["browser_download_url"]
    asset_size_mb = asset["size"] / (1024 * 1024)  # è½¬æ¢ä¸ºMB
    save_path = os.path.join(save_dir, asset_name)

    # æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²å­˜åœ¨å®Œæ•´æ–‡ä»¶ï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰
    if os.path.exists(save_path):
        local_size_mb = os.path.getsize(save_path) / (1024 * 1024)
        if abs(local_size_mb - asset_size_mb) < 0.01:  # è¯¯å·®å°äº0.01MBè§†ä¸ºå®Œæ•´
            print(f"  âœ… å·²å­˜åœ¨ï¼š{asset_name}ï¼ˆ{asset_size_mb:.2f}MBï¼‰")
            return True

    # æµå¼ä¸‹è½½ï¼ˆæ”¯æŒå¤§æ–‡ä»¶ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜ï¼‰
    print(f"  ğŸ“¥ ä¸‹è½½ä¸­ï¼š{asset_name}ï¼ˆ{asset_size_mb:.2f}MBï¼‰")
    try:
        with requests.get(
                download_url,
                headers={"Authorization": f"token {GITHUB_TOKEN}"} if GITHUB_TOKEN else {},
                stream=True,
                timeout=60
        ) as resp:
            resp.raise_for_status()
            with open(save_path, "wb") as f:
                total_size = int(resp.headers.get("content-length", 0))
                downloaded_size = 0
                for chunk in resp.iter_content(chunk_size=8192):  # 8KBåˆ†ç‰‡å†™å…¥
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        # æ˜¾ç¤ºä¸‹è½½è¿›åº¦ï¼ˆä»…å½“èƒ½è·å–æ€»å¤§å°æ—¶ï¼‰
                        if total_size > 0:
                            progress = (downloaded_size / total_size) * 100
                            print(f"\r  è¿›åº¦ï¼š{progress:.1f}%", end="")
        print(f"\n  âœ… ä¸‹è½½å®Œæˆï¼š{asset_name}")
        return True
    except Exception as e:
        print(f"\n  âŒ ä¸‹è½½å¤±è´¥ï¼š{asset_name} - {str(e)}")
        # æ¸…ç†æœªä¸‹è½½å®Œæˆçš„æ–‡ä»¶
        if os.path.exists(save_path) and os.path.getsize(save_path) < asset["size"]:
            os.remove(save_path)
        return False


# ------------------- æ ¸å¿ƒé€»è¾‘ï¼šå•ä»“åº“å¤„ç† -------------------
def process_single_repo(repo_config: Dict, all_states: Dict[str, Dict[int, str]], max_versions: int = MAX_VERSIONS) -> Dict[str, Dict[int, str]]:
    """å¤„ç†å•ä¸ªä»“åº“çš„å¢é‡ä¸‹è½½ï¼Œè¿”å›æ›´æ–°åçš„å…¨å±€çŠ¶æ€"""
    # æå–å½“å‰ä»“åº“é…ç½®
    repo_owner = repo_config["repo_owner"]
    repo_name = repo_config["repo_name"]
    base_save_dir = repo_config["base_save_dir"]
    state_key = repo_config["state_key"]
    # æœ€ç»ˆä¿å­˜ç›®å½•ï¼šåŸºç¡€ç›®å½•/ä»“åº“å/ç‰ˆæœ¬å·ï¼ˆå¦‚./Releases/dnSpy/v6.2.0ï¼‰
    repo_root_dir = os.path.join(base_save_dir, repo_name)

    # æ‰“å°ä»“åº“å¤„ç†ä¿¡æ¯
    print(f"\n" + "=" * 70)
    print(f"ğŸ“¦ å¼€å§‹å¤„ç†ä»“åº“ï¼š{repo_owner}/{repo_name}")
    print(f"  - ä»“åº“æ ¹ç›®å½•ï¼š{os.path.abspath(repo_root_dir)}")
    print(f"  - çŠ¶æ€æ–‡ä»¶ï¼š{os.path.abspath(STATE_FILE)}")
    print(f"  - ä»…è·å–æœ€æ–°çš„ {max_versions} ä¸ªç‰ˆæœ¬")
    print("=" * 70)

    # 1. åˆå§‹åŒ–ä»“åº“æ ¹ç›®å½•
    os.makedirs(repo_root_dir, exist_ok=True)

    # 2. åŠ è½½å½“å‰ä»“åº“çš„å·²ä¸‹è½½çŠ¶æ€
    repo_state = all_states.get(state_key, {})
    print(f"  â„¹ï¸  å·²ä¸‹è½½æ–‡ä»¶æ•°é‡ï¼š{len(repo_state)} ä¸ª")

    try:
        # 3. è·å–ä»“åº“æœ€æ–°çš„Releases
        releases = fetch_repo_releases(repo_owner, repo_name, max_versions)
        if not releases:
            print(f"  âš ï¸  æœªè·å–åˆ°ä»»ä½•Releasesï¼ˆå¯èƒ½ä»“åº“æ— Releaseæˆ–æƒé™ä¸è¶³ï¼‰")
            return all_states
        print(f"  â„¹ï¸  è·å–åˆ°çš„Releasesæ•°é‡ï¼š{len(releases)} ä¸ª")

        # 4. ç­›é€‰æœªä¸‹è½½çš„é™„ä»¶ï¼ˆåŸºäºçŠ¶æ€æ–‡ä»¶ä¸­çš„Asset IDï¼‰
        undownloaded_assets = []
        for release in releases:
            release_version = sanitize_version(release["tag_name"])  # æ¸…ç†ç‰ˆæœ¬å·
            for asset in release["assets"]:
                if asset["id"] not in repo_state:
                    asset["version"] = release_version  # ç»™é™„ä»¶ç»‘å®šç‰ˆæœ¬ä¿¡æ¯
                    undownloaded_assets.append(asset)

        if not undownloaded_assets:
            print(f"  ğŸ‰ æ— æ–°æ–‡ä»¶éœ€è¦æ›´æ–°ï¼Œæ‰€æœ‰é™„ä»¶å‡å·²ä¸‹è½½")
            return all_states
        print(f"  ğŸ” å‘ç°æœªä¸‹è½½æ–‡ä»¶ï¼š{len(undownloaded_assets)} ä¸ª")

        # 5. ä¸‹è½½æœªä¸‹è½½çš„é™„ä»¶å¹¶æ›´æ–°çŠ¶æ€
        success_count = 0
        for asset in undownloaded_assets:
            # ä¸ºå½“å‰ç‰ˆæœ¬åˆ›å»ºå•ç‹¬ç›®å½•
            version_dir = os.path.join(repo_root_dir, asset["version"])
            os.makedirs(version_dir, exist_ok=True)

            # ä¸‹è½½é™„ä»¶å¹¶è®°å½•çŠ¶æ€
            if download_asset(asset, version_dir):
                repo_state[asset["id"]] = asset["name"]
                success_count += 1

        # 6. æ›´æ–°å…¨å±€çŠ¶æ€
        all_states[state_key] = repo_state

        # 7. æ‰“å°å¤„ç†ç»“æœ
        print(f"\n  ğŸ“Š ä»“åº“å¤„ç†å®Œæˆï¼")
        print(f"  - æœ¬æ¬¡æˆåŠŸä¸‹è½½ï¼š{success_count} ä¸ªæ–‡ä»¶")
        print(f"  - ç´¯è®¡å·²ä¸‹è½½ï¼š{len(repo_state)} ä¸ªæ–‡ä»¶")

    except Exception as e:
        print(f"  âŒ ä»“åº“å¤„ç†å¤±è´¥ï¼š{str(e)}")

    return all_states


def get_github_readme_content(repo_config: Dict):
    # 1. æ„é€  GitHub API è¯·æ±‚ URLï¼ˆè·å– README ä¿¡æ¯ï¼‰
    repo_owner = repo_config["repo_owner"]
    repo_name = repo_config["repo_name"]
    base_save_dir = repo_config["base_save_dir"]
    repo_root_dir = os.path.join(base_save_dir, repo_name)
    api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/readme"

    try:
        # 2. å‘é€ GET è¯·æ±‚ï¼ˆæ— éœ€è®¤è¯ï¼Œå…¬å¼€ä»“åº“å¯ç›´æ¥è®¿é—®ï¼‰
        response = requests.get(api_url)
        # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸï¼ˆ200 è¡¨ç¤ºæˆåŠŸï¼‰
        response.raise_for_status()

        # 3. è§£æ JSON å“åº”ï¼Œæå– download_url å’Œ Base64 ç¼–ç çš„å†…å®¹
        readme_info = response.json()
        download_url = readme_info.get("download_url")  # æå–ä¸‹è½½é“¾æ¥
        base64_content = readme_info.get("content")  # æå– Base64 ç¼–ç çš„å†…å®¹

        if not download_url or not base64_content:
            print("Error: æœªæ‰¾åˆ° download_url æˆ– README å†…å®¹")
            return None

        # 4. è§£ç  Base64 å†…å®¹ï¼ˆæ³¨æ„å»é™¤æ¢è¡Œç¬¦ï¼ŒBase64 ç¼–ç ä¸å…è®¸å¤šä½™æ¢è¡Œï¼‰
        base64_content_clean = base64_content.replace("\n", "")  # æ¸…ç†ç¼–ç å†…å®¹
        decoded_content = base64.b64decode(base64_content_clean).decode("utf-8")  # è§£ç ä¸º UTF-8 æ–‡æœ¬
        # ï¼ˆå¯é€‰ï¼‰å°†å†…å®¹å†™å…¥æœ¬åœ°æ–‡ä»¶
        with open(f"{repo_root_dir}/ReadMe.md", "w", encoding="utf-8") as f:
            f.write(decoded_content)
        print(f"README.md å·²ä¿å­˜åˆ°æœ¬åœ°ï¼š{repo_root_dir}/ReadMe.md")

        return decoded_content

    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚å¤±è´¥ï¼š{e}")
        return None


# ------------------- ä¸»å‡½æ•°ï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰ä»“åº“ -------------------
def main():
    print("=" * 70)
    print(f"ğŸš€ å¤šä»“åº“GitHub Releaseså¢é‡ä¸‹è½½å·¥å…·ï¼ˆYAMLé…ç½®ç‰ˆï¼‰")
    print(f"  - ä»…è·å–æœ€æ–°çš„ {MAX_VERSIONS} ä¸ªç‰ˆæœ¬")
    print("=" * 70)

    try:
        # 1. åŠ è½½YAMLä»“åº“é…ç½®
        REPOS_CONFIG = load_repo_configs_from_yaml(REPO_CONFIG_YAML)
        print(f"â„¹ï¸  ä»YAMLåŠ è½½é…ç½®æˆåŠŸï¼Œå…± {len(REPOS_CONFIG)} ä¸ªä»“åº“")
    except (FileNotFoundError, yaml.YAMLError, ValueError) as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥ï¼š{str(e)}")
        return

    # 2. åŠ è½½å…¨å±€ä¸‹è½½çŠ¶æ€
    all_states = load_all_repos_downloaded_state()

    # 3. éå†æ‰€æœ‰ä»“åº“æ‰¹é‡å¤„ç†
    for repo_idx, repo_config in enumerate(REPOS_CONFIG, 1):
        print(f"\nã€{repo_idx}/{len(REPOS_CONFIG)}ã€‘")
        all_states = process_single_repo(repo_config, all_states)
        # æ¯å¤„ç†å®Œä¸€ä¸ªä»“åº“ä¿å­˜ä¸€æ¬¡çŠ¶æ€ï¼Œé¿å…æ„å¤–ä¸¢å¤±
        save_all_repos_downloaded_state(all_states)

    # 4. æ‰“å°æœ€ç»ˆç»“æœ
    print(f"\n" + "=" * 70)
    print(f"âœ… æ‰€æœ‰ä»“åº“å¤„ç†å®Œæ¯•ï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()